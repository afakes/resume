[
  {    
    "type": "page",
    "heading": "Adam Fakes",
    "summary": "Data Engineering | Data Science | Software Engineering | Geospatial analysis",
    "image":   "https://adamfakes.com/images/AdamFakes-hard-colour-li.jpg"
  },
  {
    "type": "contact",
    "title": "contact",
    "image": "https://adamfakes.com/images/Sight.JPG",
    "articles": [
      {
        
        "key_value": [
          {"key":"email",       "value":"adam@datavi.co" },
          {"key":"phone",       "value":"0401-302243" },
          {"key":"physical",    "value":"Melbourne, Victoria, Australia" },
          {"key":"LinkedIn",    "value":"https://www.linkedin.com/in/adamfakes" },
          {"key":"github",      "value":"https://github.com/afakes/portfolio" },
          {"key":"portfolio",   "value":"https://adamfakes.my.canva.site/" },
          {"key":"website",     "value":"https://adamfakes.com" },
          {"key":"google meet", "value":"https://meet.google.com/omv-aizq-vrj" }
        ]
      }
    ]
  },
  {
    "type": "summary",
    "title": "SUMMARY",
    "articles": [
      { 
        "summary":    "make it work, make it better",
        "points": [
          "I have over 25 years experience as a data engineer, cloud engineer, software engineer, scientist, geo-spatial analyst, for government bodies, technology companies, small to medium enterprises, university, scientific & gaming organisations. ",
          "I am well qualified with industry achievements and a Bachelor of science, with majors in computer science, environmental science and hydrology. He has a unique ability to recognise systems, data structures and dependencies to design, build, integrate and automate business processes. ",
          "I have contributed to the success of projects in government entities, technology firms, universities, scientific institutions, and gaming companies. Coupled with a Bachelor's degree in Computer Science and a proven track record of accomplishments in the industry. I am skilled at systems architecture, data structures, inter-dependencies identification, software and data engineering",
          "My expertise lies in designing, building, integrating, and automating complex systems with a unique blend of precision, innovation and creativity."
        ]
      }
    ]
  },
  
  {
    "type": "education",
    "title": "EDUCATION",
    "articles": [
      {
        "heading":     "Bachelor of Science: Computer science + Environmental science",
        "subheading":  "James Cook University (2012)",
        "summary":     "Computer Science, Environmental Science, Hydrology, Geospatial Analysis"
      },
      {
        "heading":     "Diploma of Computing",
        "subheading":  "Newcastle University (1994)",
        "summary":     "Database design, programming"
      }
    ] 
  },

  {
    "type": "skills",
    "title": "KEY SKILLS",
    "articles": [
      {
        "heading": "LEADERSHIP",
        "summary": "team leadership | stakeholder management | mentoring",
        "key_value": [
          {"key": "13", "value":"Mentoring Developers, Masters & PhD students"},
          {"key":  "5", "value":"Commercial Stakeholder engagement"},
          {"key":  "5", "value":"AGILE Development + Project management"},
          {"key":  "5", "value":"Management & Leadership"}
        ]
      },
      {
        "heading": "DATA ENGINEERING",
        "summary": "orchestration | data engineering | governance | statistics | modelling | integration",
        "key_value": [
          {"key":"18", "value":"python development"},
          {"key":"16", "value":"database - schema design, development, administration, query tuning "},
          {"key":"16", "value":"geo-spatial analysis (ArcGIS, QGIS, remote-sensing)"},
          {"key":"12", "value":"mysql - schema design & development "},
          {"key":"12", "value":"API Development - REST (AWS API Gateway, Google Functions, Apache)"},
          {"key": "5", "value":"PostgreSQL - schema design & development "},
          {"key":"11", "value":"data management - collection, auditing, governance, storage"},
          {"key":"10", "value":"AWS api-gateway, lambda, ecs + ecr "},
          {"key": "6", "value":"data-pipeline orchestration – Jenkins "},
          {"key": "8", "value":"Statistical analysis linear + geo-spatial"},
          {"key": "8", "value":"pipelines orchestration, github-actions, jenkins "},
          {"key": "4", "value":"Google Compute (GCP), storage, create & deploy functions, security"},
          {"key": "4", "value":"geo-spatial analysis (multi-spectral remote-sensing)"},
          {"key": "3", "value":"data visualisation (aws quicksight, power-bi, looker data studio)"},
          {"key": "2", "value":"XML, Xslt, SOAP, SensorML, presented public lectures"},
          {"key": "3", "value":"databricks, notebook creation, data management, heterogeneous data access"},
          {"key": "1", "value":"data-pipeline orchestration – Airflow DAG development"}  
        ]
      },
      {
        "heading": "SOFTWARE ENGINEERING",
        "summary": "computation modelling | machine learning | software engineering | code development | refactoring | deep-learning",
        "key_value": [
          {"key": "20", "value":"Software Development, Software Engineering"},
          {"key": "18", "value":"Python Development"},
          {"key": "15", "value":"Python statistics (sk-learn)"},
          {"key": "15", "value":"Code management git, github, svn, peer review, bitbucket"},
          {"key": "14", "value":"Machine Learning - Clustering, Predictive, Modelling  e.g. ARIMA "},
          {"key": "12", "value":"API Development - REST (AWS API Gateway, Google Functions, Apache"},
          {"key": "12", "value":"Python geospatial data"},
          {"key":  "9", "value":"PHP Development"},
          {"key":  "2", "value":"Payment gateways Adyen, PayPal, Visa"},
          {"key":  "3", "value":"C++ re-engineering"}
        ]
      },
      {
        "heading": "WEB DEVELOPMENT",
        "summary": "user interface design | user interface development | responsive layout | api integration",
        "key_value": [
          {"key": "18", "value":"Web development, CSS3, HTML5, jQuery"},
          {"key": "18", "value":"NodeJS, JavaScript, ECMAScript Development"},
          {"key":  "9", "value":"Linux Web Application development (Apache, MySQL, Python, PHP)"},
          {"key":  "6", "value":"Apache configuration and Management"},
          {"key":  "4", "value":"Javascript development *Web Components)"},
          {"key":  "2", "value":"React development"}
        ]
      },
      {
        "heading": "INFRASTRUCTURE",
        "summary": "cloud engineering | api development | security | authentication | authorization",
        "key_value": [
          {"key": "11", "value":"Amazon Web Services (AWS)"},
          {"key": "13", "value":"Linux - RHEL, Debian, Ubuntu, systems administration (daemons & services, file-systems)"},
          {"key":  "8", "value":"AWS EC2, infrastructure as code (cloud-formation), load balancing, auditing"},
          {"key":  "9", "value":"Unix infrastructure management"},
          {"key":  "7", "value":"Linux application development (CLI, ncurses, GTK)"}          
        ]
      }

    ] 
  },
  {
    "type":"experience",
    "title":"EXPERIENCE",
    "articles": [
      {
        "date": {"from": "Dec 2022", "to": "MAY 2024"},
        "heading": "Senior Engineer",
        "subheading": "Regrow.ag (remote)",
        "summary": "DATA ENGINEERING | SOFTWARE ENGINEERING",
        "points": [
          "Led the refactor and re-architecture efforts for our core SaaS product, focusing on enhancing code quality and minimising defects. Introduced SonarCube's Complexity metrics to improve code maintainability.",
          "Redesigned, and developed the data-exchange interface, between the main product and the contract/document management system Docusign.",
          "Created Geo-spatial datasets tailored to support producers across the EU, USA, and Australia in managing their crop and farming practices efficiently using open source QGIS geo-spatial tool to perform spatial analysis.",
          "Engaged in Python Software Engineering tasks, constructing FastAPI and Pydantic-based modules for storing Climate Data sourced from primary producers and third-party data providers.",
          "Developed and implemented Geo-spatial algorithms and integrations with machine learning models in using Python, Fast API, and Pydantic.",
          "Authored internal Software Engineering guides to facilitate knowledge sharing and standardisation within the team."
        ]
      },
      {
        "date": {"from": "Nov 2021", "to": "Dec 2022"},
        "heading": "Head of Technology",
        "subheading": "RUBIX (Melbourne, Australia)",
        "summary": "PEOPLE LEADER | DATA ENGINEER | SOFTWARE ENGINEER",
        "points": [
          "Management and Leadership: Oversaw day-to-day operations and work package assignments for a dynamically sized team, ranging from 4 to 15 members. Managed people and project funding allocations, providing executive-level reporting. Notably, established and led the Software as a Service team and its product portfolio from inception to commercial delivery.",
          "Budget Management: Successfully managed budgets exceeding $1 million, including meticulous work forecasting to ensure efficient resource allocation (people, infrastructure and expertise).",
          "Business Proposals: Authored comprehensive proposals for Data System builds, encompassing client requirement alignment, business and use case development, and end-to-end technology and resource cost analysis.",
          "Solution Architecture: Designed, developed, and managed the delivery of ReefBuilder, an Environmental data capture and reporting platform. Developed the framework, for a Python code base, dev-ops methodology driven as an Infrastructure as Code (IaC) deployment system, using AWS cloud development kit (CDK). Additionally, created a simplified JavaScript to Python interface using AWS API gateway for Lambda or Apache-executed processes.",
          "SaaS product delivery: Established a 'Data Marketplace' using Shopify for the curated retail sale of Machine Learning ready datasets. Developed all Python-based APIs. Implemented a system where data is initially stored as CSV and dynamically converted to various requested formats such as CSV, JSON, Parquet and API payloads, and stored in S3. This system made extensive use of Pandas, GeoPandas, Numpy and Scikit-learn for statistical analysis (Normal distribution calculations).",
          "Data Engineering: Designed and implemented Python-based data extraction, transformation, and loading (ETL) pipelines across Lambda, ECS, and EC2 environments to facilitate periodic download, cleansing, loading, and storage of data. Built out a number of Databricks Proof-of-concept notebooks (SQL, R, Python, Markdown) to demonstrate various data analysis, prediction and transformation techniques."
        ]
      },
      {
        "date": {"from": "Apr 2019", "to": "Nov 2021"},
        "heading": "Senior Engineer",
        "subheading": "RUBIX (Consulting @ National Australia Bank)",
        "summary": "DATA ENGINEER | CLOUD ENGINEER | SOFTWARE ENGINEER",
        "points": [          
          "Mentorship and Leadership: Development and delivery of comprehensive training sessions for new team members. Topics covered included the significance of, and methodologies for, conducting Peer Reviews, code readability, code maintainability, Test Driven Development, Domain Driven Development and bug minimisation though the use of tools like SonarCube.",
          "Data engineering: Big-data pipelines: creation, management, and maintenance of data pipelines (ETL). Development of python functions, class and data structures to facilitate the acquisition, transformation, quality assurance and delivery of data from multiple legacy systems, (mainframes, AS400 etc) into S3 data-stores, using AWS Athena & Glue.",
          "AWS Cloud Engineering: Led the design and development of Python / Jenkins / Airflow data extraction and transformation pipelines tailored for execution in Lambda + Elastic Container Store (ECS) or EC2 environments. Proficiently managed data transport and conversions, to support terabytes of data.",
          "AWS Cloud DevOps: Engineered robust code generation tooling, facilitating the construction and deployment of micro-services using Elastic Container Services, Virtual Private Clouds (VPCs), and Virtual Machines (EC2) using Terraform and Cloud-formation.",
          "Code Quality Control: Led the conversion of requirements and implemented code to effectively monitor and rectify real-time data quality issues. Established code quality metrics, ways-of-working and dashboard visualisations in Splunk."
        ]
      },
      {
        "date": {"from": "Nov 2017", "to": "Mar 2019"},
        "heading": "SENIOR ENGINEER (Observability)",
        "subheading": "MYOB (Melbourne, Australia)",
        "summary": "DATA ENGINEER | CLOUD ENGINEER | SOFTWARE ENGINEER | DEVOPS",
        "points": [
          "Created AWS Cloud-formation templates to build, manage, and monitor data pipelines, integrating with Kinesis, S3, and the Sumo Logic SaaS platform. These pipelines supported ETL processes handling up to 200GB of data.",
          "Designed and delivered training courses on SumoLogic usage, focusing on data acquisition and Observability techniques, titled ‘How to find your data (problems)’",
          "Developed several applications utilising Python, within Docker containers, running on both Kubernetes and AWS Fargate, to bolster fraud detection capabilities.",
          "Offered DevOps expertise and infrastructure support to international teams, providing insights and guidance to enhance operational efficiency."
        ]
      },
      {
        "date": {"from": "Sep 2015", "to": "Oct 2017"},
        "heading": "SENIOR ENGINEER",
        "subheading": "TABCorp (Melbourne, Australia)",
        "summary": "DATA ENGINEER | CLOUD ENGINEER | SOFTWARE ENGINEER | DEVOPS",
        "points": [
          "Engineered AWS Cloud-formation templates to facilitate the construction of an API gateway paired with Python Lambda ETL functions. These components seamlessly delivered risk and fraud detection data streams to the Salesforce SaaS platform.",
          "Designed and implemented a secure and traceable credit card Payment gateway for sunbets.co.uk. The gateway integrated with anti-money laundering (AML) systems, ensuring robust transactional security. Within six months of operation, the gateway processed over £60 million with an error margin of less than £10,000.",
          "Developed and maintained various features and fixes in PHP for the Luxbet.com.au gaming platform. These enhancements bolstered customer retention, ensured system stability, and facilitated the roll-out of new betting markets.",
          "Leveraged Python, open-source QuantumGIS (QGIS) for geo-spatial data analysis to support retail teams in vendor payments, employing an innovative approach tailored for non-traditional venues."
        ]
      },
      {
        "date": {"from": "Aug 2014", "to": "Aug 2015"},
        "heading": "Software Engineer",
        "subheading": "SMS Global (Melbourne, Australia)",
        "summary": "DATA ENGINEER | SOFTWARE ENGINEER",
        "points": [
          "Created PHP integrations linking the short-message-service (SMS) delivery platform with various 3rd party REST APIs, such as Xero accounting and the Zapier.com platform.",
          "Designed and implemented multiple Zapier 'zaps' to enable customers to seamlessly upload their Google contacts into our platform, send bulk messages using a Google Sheet, and receive reports from our system directly into Google Sheets.",
          "Restructured a client's Linux, Apache, MySQL, PHP (LAMP) application into a multi-tier model-view-controller (MVC) pattern web application. Hosted on AWS, the redeveloped application incorporated secure-socket-layer (SSL), virtual load balancers, multiple EC2 instances, a MySQL back-end, and dynamically attached elastic-block-store (EBS) volumes for enhanced scalability and performance."
        ]
      },
      {
        "date": {"from": "Jun 2013", "to": "Jul 2014"},
        "heading": "TECHNOLOGY MANAGER",
        "subheading": "Victorian Greens Party (Melbourne, Australia)",
        "summary": "DATA MANAGER| SOFTWARE ENGINEER | CLOUD INFRASTRUCTURE ADMINISTRATION",
        "points": [
          "Oversaw the transition to the cloud, leading the migration of the Victorian office from an on-site email and shared files service to a hosted VPS. Managed the entire process to minimise costs and ensure backup services were in place.",
          "Engineered an ETL adaptor using PHP to seamlessly integrate the Nation-builder SaaS platform with the internal Drupal system of the Greens.",
          "Administered Unix servers, overseeing tasks such as local and remote email server management, as well as implementing SPAM and anti-virus detection measures."          
        ]
      },
      {
        "date": {"from": "Mar 2013", "to": "May 2013"},
        "heading": "ENGINEER",
        "subheading": "Victorian Department of Primary Industries (contract)",
        "summary": "GEO-SPATIAL DATA ANALYST | DATA ENGINEER | SOFTWARE ENGINEER ",
        "points": [
          "Implemented a new Geo-spatial user interface within the Exploration Licensing system, enabling users to visualise licensee locations through map views.",
          "Revamped and translated Oracle stored procedures into PHP, streamlining the process of transforming Excel spreadsheets into Oracle tables.",
          "Adapted MS-Windows specific code, originally utilising ODBC Microsoft SQL Server connections, to run on an Oracle with a Linux back-end.",
          "Developed Python scripts and MySQL stored procedure ETL processes, validation, and bounds checking, while also performing linear, geo-spatial, and time-series statistical analysis.",
          "Conducted analysis on geographic and satellite remote sensing datasets, generating geographic datasets, cartographic imagery, and figures for publication in journal articles."
        ]
      },
      {
        "date": {"from": "Sep 2012", "to": "Jan 2013"},
        "heading": "DATA ANALYST",
        "subheading": "James Cook University - Human Footprint Project (Cairns, Australia)",
        "summary": "GEO-SPATIAL DATA ANALYSIS",
        "points": [
          "Researched, obtained, analysed, and processed geo-spatial datasets for projects focused on Human-Footprint and Human Influence indices.",
          "Created Python-based plugins for QGIS to implement the supervisor's research algorithms"
        ]
      },
      {
        "date": {"from": "May 2011", "to": "Oct 2012"},
        "heading": "Engineer",
        "subheading": "James Cook University - eResearch (Cairns, Australia)",
        "summary": "DATA ENGINEER | SOFTWARE ENGINEER | SCIENCE RESEARCH",
        "points": [
          "Embedded within the eResearch Department, I implemented AGILE and SDLC methodologies to architect and build a web application. Leveraging jQuery, Python, and MySQL, the application facilitated the ingestion and analysis of biological and environmental data, culminating in interactive visualisations of species ranges juxtaposed against diverse Climate Change scenarios, CliMAS: Climate Maps for Australian Species",
          "Additionally, I developed an array of Python, PHP, Bash, and C++ components to interface with High Performance Compute clusters. These components executed computational and geo-statistical models driven by research, employing map-reduce techniques to parallelise execution and streamline payload management."
        ]
      },
      {
        "date": {"from": "Apr 2010", "to": "May 2011"},
        "heading": "Principal investigator",
        "subheading": "James Cook University - Hydrology/Ecology Research (Cairns, Australia)",
        "summary": "SCIENCE RESEARCHER | DATA ENGINEER | HARDWARE + SOFTWARE ENGINEER",
        "points": [
          "Led a Queensland Cyber Infrastructure Foundation (QCIF) project as principal investigator to construct a 'Smart Water Sensor Network', involving the development of a proof-of-concept system, primarily using off-the-shelf components complemented by custom-built code. The system was designed for deployment in remote locations to monitor a homogeneous array of sensors and transmit data via satellite link.",
          "Designed and implemented a proof-of-concept sensor communication data exchange system for a range of commercial and in-house sensor platforms. Required the development of efficient python code to run on battery powered devices."
        ],
        "link": [
          {
            "heading": "Sap flow monitoring",
            "image": "https://raw.githubusercontent.com/afakes/resume/master/images/SapFlowMonitoringTN.PNG",
            "text": "Using Heat Field deformation to track sap flow inside living trees"
          },
          {
            "heading": "Climate monitoring",
            "image": "https://raw.githubusercontent.com/afakes/resume/master/images/ClimateMonitoringTN.JPG",
            "text": "Climate monitoring stations in the field"
          }
        ]
      },
      {
        "date": {"from": "Apr 2009", "to": "Apr 2010"},
        "heading": "Science Researcher",
        "subheading": "James Cook University - Hydrology/Ecology Research (Cairns, Australia)",
        "summary": "SCIENCE RESEARCHER | DATA ENGINEER | HARDWARE + SOFTWARE ENGINEER",
        "points": [
          "Created a unified database to standardise Australian State groundwater readings, incorporating supplementary environmental data from various global sources including NASA, European Space Agency, and GRACE gravity anomaly data. This project necessitated the development of extensive code-bases utilising Linux, Python, and MySQL.",
          "Conducted analysis on geographic and satellite remote sensing datasets to generate geographic datasets, cartographic imagery, and figures for publication in journal articles.",
          "Delivered a public lecture on XML titled ‘eXciting Markup Language’.",
          "Re-engineered C++ Artificial Neural Network code-base and data reader into Python."
        ],
        "link": [
          "https://grace.jpl.nasa.gov/mission/grace/" 
        ]
      },
      {
        "date": {"from": "Sep 2006", "to": "Apr 2009"},
        "heading": "Senior Developer",
        "subheading": "CSIRO (Cairns, Australia)",
        "summary": "SOFTWARE DEVELOPMENT | SCIENCE RESEARCH | GEO-SPATIAL DATA ANALYSIS",
        "points": [
          "Created ‘The Landscapes Toolkit”, a desktop application for MS-Windows using C# and web technologies such as HTML and CSS. This application, developed in C# .NET, supports the integration of models through a Lazy-load software pattern implementation.",
          "Designed and implemented geo-spatial and environmental modelling tools for ‘The Landscapes Toolkit’ a Scientific Model Integration environment. These tools included Python plugins to enhance functionality."
        ]
      },
      {
        "date": {"from": "Apr 2004", "to": "Apr 2006"},
        "heading": "Senior Developer",
        "subheading": "Waste Service NSW (Sydney, Australia)",
        "summary": "SOFTWARE DEVELOPER | REPORTING| INFRASTRUCTURE ADMINISTRATION",
        "points": [
          "Developed and revamped Crystal Reports, integrating them with .Net, Lotus Notes, and Microsoft Reporting Services.",
          "Managed Lotus Notes Domino cluster email services administration, which encompassed spam and virus filtering, on Windows 2003 and Citrix servers.",
          "Desktop support for 300+ users across 14 sites, including fault analysis, recording, and repair."
        ]
      },
      {
        "date": {"from": "Apr 2003", "to": "Apr 2004"},
        "heading": "Senior Developer",
        "subheading": "Salvation Army (Sydney, Australia)",
        "summary": "SOFTWARE DEVELOPMENT | DATA MANAGEMENT",
        "points": [
          "Redesigned and redeveloped an existing multi-site Lotus Notes client application into a centralised web-browser application.",
          "Designed a warehousing system to manage the specific physical item storage needs of the Army."
        ]
      },
      {
        "date": {"from": "Apr 2000", "to": "Apr 2003"},
        "heading": "Senior Developer",
        "subheading": "IBM Global Services (North Sydney, Australia)",
        "summary": "DATA ENGINEER | SOFTWARE DEVELOPER | WEB DEVELOPMENT | FINANCIAL MODELLING",
        "points": [
          "Designed and implemented a web-based Investment Management application, replacing numerous complex financial spreadsheets, while ensuring funds-management quality assurance.",
          "Engineered a back-end system for the Investment Management application to calculate multiple future predictions of managed funds, leveraging actuarial algorithms, and expert opinions.",
          "Worked closely with third-party contractors to develop a Lotus Notes password encryption transfer agent, ensuring a seamless user transition to Oracle.",
          "Collaborated with MLC and IBM as a member of the Business Continuity team to devise and execute disaster recovery plans and procedures for mlc.com.au.",
          "Developed a Lotus Notes configuration management and deployment tool for version control, streamlining deployment processes."
        ]
      }   
   ]
  },
  {
    "type": "academic",
    "title": "CO-AUTHORED JOURNAL ARTICLES",
    "articles": [
      { "points": ["Leblanc, M. et.al. (2011), Groundwater change in the Murray basin from long-term in situ monitoring and GRACE estimates Climate change effects on groundwater resources"] },
      { "points": ["Leblanc, M. et.al. (2009), Basin-scale, integrated observations of the early 21st century multi-year drought in southeast Australia, Water Resour. Res., 45"] },
      { "points": ["Bohnet, I. et.al. (2008), 'An integrated modelling framework to explore land use change scenarios in collaboration with communities and end-users', in International Conference Impact Assessment of Land Use Changes, Berlin, Germany."] }
    ]
  }
]
